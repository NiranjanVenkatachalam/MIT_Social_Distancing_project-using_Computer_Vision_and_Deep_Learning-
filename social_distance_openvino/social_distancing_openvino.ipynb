{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BOTH CODES WERE EXECUTED ON INTEL EDGE DEV CLOUD JUPYTER NOTEBOOKS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from openvino.inference_engine import IECore\n",
    "\n",
    "\n",
    "def preprocess_frame(frame, input_shape):\n",
    "    resized_frame = cv2.resize(frame, (input_shape[3], input_shape[2]))\n",
    "    processed_frame = resized_frame.transpose((2, 0, 1))\n",
    "    processed_frame = np.expand_dims(processed_frame, axis=0)\n",
    "    return processed_frame\n",
    "\n",
    "\n",
    "def draw_bounding_boxes(frame, boxes, violation_count):\n",
    "    for box in boxes:\n",
    "        x_min, y_min, x_max, y_max = box\n",
    "        cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "    cv2.putText(frame, f\"Violations: {violation_count}\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "    return frame\n",
    "\n",
    "\n",
    "def calculate_euclidean_distance(point1, point2):\n",
    "    x1, y1 = point1\n",
    "    x2, y2 = point2\n",
    "    distance = np.sqrt((x2 - x1) ** 2 + (y2 - y1) ** 2)\n",
    "    return distance\n",
    "\n",
    "\n",
    "def check_social_distancing(boxes, distance_threshold):\n",
    "    violation_count = 0\n",
    "    centers = []\n",
    "    for box in boxes:\n",
    "        center_x = (box[0] + box[2]) // 2\n",
    "        center_y = box[3]\n",
    "        centers.append((center_x, center_y))\n",
    "\n",
    "    for i, center1 in enumerate(centers):\n",
    "        for j, center2 in enumerate(centers[i + 1:], i + 1):\n",
    "            distance = calculate_euclidean_distance(center1, center2)\n",
    "            if distance < distance_threshold:\n",
    "                violation_count += 1\n",
    "                cv2.line(frame, center1, center2, (0, 0, 255), 2)\n",
    "\n",
    "    return violation_count\n",
    "\n",
    "\n",
    "# Load the OpenVINO Inference Engine\n",
    "ie = IECore()\n",
    "\n",
    "# Load the IR model files\n",
    "model_xml = \"D:/yolov5s_openvino_model/yolov5s.xml\"\n",
    "model_bin = \"D:/yolov5s_openvino_model/yolov5s.bin\"\n",
    "\n",
    "# Load the network\n",
    "net = ie.read_network(model=model_xml, weights=model_bin)\n",
    "\n",
    "# Get the input and output layer names\n",
    "input_blob = next(iter(net.input_info))\n",
    "output_blob = next(iter(net.outputs))\n",
    "\n",
    "# Load the network to the device (CPU)\n",
    "exec_net = ie.load_network(network=net, device_name=\"CPU\")\n",
    "\n",
    "# Define input and output shapes\n",
    "input_shape = net.input_info[input_blob].input_data.shape\n",
    "output_shape = net.outputs[output_blob].shape\n",
    "\n",
    "# Define the distance threshold for social distancing\n",
    "distance_threshold = 100\n",
    "\n",
    "# Open the video file\n",
    "video_path = \"D:/inputs/mall_area.mp4\"\n",
    "video = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Create a VideoWriter object to save the output video\n",
    "output_path = \"D:/results/social_distance_detection.avi\"\n",
    "output_width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "output_height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = video.get(cv2.CAP_PROP_FPS)\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
    "video_writer = cv2.VideoWriter(output_path, fourcc, fps, (output_width, output_height))\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Preprocess the frame\n",
    "    processed_frame = preprocess_frame(frame, input_shape)\n",
    "\n",
    "    # Run inference\n",
    "    outputs = exec_net.infer(inputs={input_blob: processed_frame})\n",
    "\n",
    "    # Parse the output\n",
    "    output = outputs[output_blob][0]\n",
    "\n",
    "    # Filter detections with confidence above a threshold\n",
    "    detections = output[output[:, 4] > 0.5]\n",
    "\n",
    "    # Extract bounding boxes\n",
    "    boxes = detections[:, :4].astype(int)\n",
    "\n",
    "    # Draw bounding boxes and check social distancing\n",
    "    frame = draw_bounding_boxes(frame, boxes, check_social_distancing(boxes, distance_threshold))\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow(\"Social Distance Detection\", frame)\n",
    "    video_writer.write(frame)\n",
    "\n",
    "    # Exit if the 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "video.release()\n",
    "video_writer.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:8: DeprecationWarning: invalid escape sequence '\\s'\n",
      "<>:9: DeprecationWarning: invalid escape sequence '\\s'\n",
      "<>:38: DeprecationWarning: invalid escape sequence '\\s'\n",
      "<>:45: DeprecationWarning: invalid escape sequence '\\s'\n",
      "<>:8: DeprecationWarning: invalid escape sequence '\\s'\n",
      "<>:9: DeprecationWarning: invalid escape sequence '\\s'\n",
      "<>:38: DeprecationWarning: invalid escape sequence '\\s'\n",
      "<>:45: DeprecationWarning: invalid escape sequence '\\s'\n",
      "C:\\Users\\NIRANJAN\\AppData\\Local\\Temp\\ipykernel_15732\\3921957851.py:8: DeprecationWarning: invalid escape sequence '\\s'\n",
      "  model_xml = \"C:\\vs\\social_distance\\social_distance_openvino\\yolov5_ir\\FP_16\\person-reidentification-retail-0286.xml\"\n",
      "C:\\Users\\NIRANJAN\\AppData\\Local\\Temp\\ipykernel_15732\\3921957851.py:9: DeprecationWarning: invalid escape sequence '\\s'\n",
      "  model_bin = \"C:\\vs\\social_distance\\social_distance_openvino\\yolov5_ir\\FP_16\\person-reidentification-retail-0286.xml\"\n",
      "C:\\Users\\NIRANJAN\\AppData\\Local\\Temp\\ipykernel_15732\\3921957851.py:38: DeprecationWarning: invalid escape sequence '\\s'\n",
      "  video = cv2.VideoCapture(\"C:\\vs\\social_distance\\social_distance_openvino\\inputs\\street_area.mp4\")\n",
      "C:\\Users\\NIRANJAN\\AppData\\Local\\Temp\\ipykernel_15732\\3921957851.py:45: DeprecationWarning: invalid escape sequence '\\s'\n",
      "  writer = cv2.VideoWriter('C:\\vs\\social_distance\\social_distance_openvino\\results\\social_distance_openvino_optimized_version.avi', fourcc, 30,(width,height), True)\n",
      "C:\\Users\\NIRANJAN\\AppData\\Local\\Temp\\ipykernel_15732\\3921957851.py:8: DeprecationWarning: invalid escape sequence '\\s'\n",
      "  model_xml = \"C:\\vs\\social_distance\\social_distance_openvino\\yolov5_ir\\FP_16\\person-reidentification-retail-0286.xml\"\n",
      "C:\\Users\\NIRANJAN\\AppData\\Local\\Temp\\ipykernel_15732\\3921957851.py:9: DeprecationWarning: invalid escape sequence '\\s'\n",
      "  model_bin = \"C:\\vs\\social_distance\\social_distance_openvino\\yolov5_ir\\FP_16\\person-reidentification-retail-0286.xml\"\n",
      "C:\\Users\\NIRANJAN\\AppData\\Local\\Temp\\ipykernel_15732\\3921957851.py:38: DeprecationWarning: invalid escape sequence '\\s'\n",
      "  video = cv2.VideoCapture(\"C:\\vs\\social_distance\\social_distance_openvino\\inputs\\street_area.mp4\")\n",
      "C:\\Users\\NIRANJAN\\AppData\\Local\\Temp\\ipykernel_15732\\3921957851.py:45: DeprecationWarning: invalid escape sequence '\\s'\n",
      "  writer = cv2.VideoWriter('C:\\vs\\social_distance\\social_distance_openvino\\results\\social_distance_openvino_optimized_version.avi', fourcc, 30,(width,height), True)\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Path to the model C:\u000bs\\social_distance\\social_distance_openvino\\yolov5_ir\\FP_16\\person-reidentification-retail-0286.xml doesn't exist or it's a directory",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m model_bin \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mC:\u001b[39m\u001b[39m\\v\u001b[39;00m\u001b[39ms\u001b[39m\u001b[39m\\\u001b[39m\u001b[39msocial_distance\u001b[39m\u001b[39m\\\u001b[39m\u001b[39msocial_distance_openvino\u001b[39m\u001b[39m\\\u001b[39m\u001b[39myolov5_ir\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mFP_16\u001b[39m\u001b[39m\\\u001b[39m\u001b[39mperson-reidentification-retail-0286.xml\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     11\u001b[0m ie \u001b[39m=\u001b[39m IECore()\n\u001b[1;32m---> 12\u001b[0m net \u001b[39m=\u001b[39m ie\u001b[39m.\u001b[39;49mread_network(model\u001b[39m=\u001b[39;49mmodel_xml, weights\u001b[39m=\u001b[39;49mmodel_bin)\n\u001b[0;32m     14\u001b[0m \u001b[39m# Get the input and output layer names\u001b[39;00m\n\u001b[0;32m     15\u001b[0m input_blob \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(net\u001b[39m.\u001b[39minput_info))\n",
      "File \u001b[1;32mie_api.pyx:368\u001b[0m, in \u001b[0;36mopenvino.inference_engine.ie_api.IECore.read_network\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mie_api.pyx:402\u001b[0m, in \u001b[0;36mopenvino.inference_engine.ie_api.IECore.read_network\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: Path to the model C:\u000bs\\social_distance\\social_distance_openvino\\yolov5_ir\\FP_16\\person-reidentification-retail-0286.xml doesn't exist or it's a directory"
     ]
    }
   ],
   "source": [
    "# Import OpenVINO modules\n",
    "import openvino\n",
    "from openvino.inference_engine import IECore, IENetwork\n",
    "import openvino.runtime as ov\n",
    "import time\n",
    "\n",
    "# Load the IR model files\n",
    "model_xml = \"C:\\vs\\social_distance\\social_distance_openvino\\yolov5_ir\\FP_16\\person-reidentification-retail-0286.xml\"\n",
    "model_bin = \"C:\\vs\\social_distance\\social_distance_openvino\\yolov5_ir\\FP_16\\person-reidentification-retail-0286.xml\"\n",
    "\n",
    "ie = IECore()\n",
    "net = ie.read_network(model=model_xml, weights=model_bin)\n",
    "\n",
    "# Get the input and output layer names\n",
    "input_blob = next(iter(net.input_info))\n",
    "output_blob = next(iter(net.outputs)) \n",
    "\n",
    "print(net.outputs.keys())\n",
    "\n",
    "# Load the network to the device (CPU, GPU, etc.)\n",
    "core = ov.Core()\n",
    "model = core.compile_model(model_xml,\"CPU\")\n",
    "\n",
    "\n",
    "\n",
    "# Define a function to compute the Euclidean distance between two points\n",
    "def euclidean_distance(a, b):\n",
    "    return np.sqrt(np.sum((a - b) ** 2))\n",
    "\n",
    "# Define a threshold for the minimum distance between people\n",
    "distance_threshold = 200 # pixels\n",
    "\n",
    "# Read and preprocess the input video\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "#give the input video\n",
    "video = cv2.VideoCapture(\"C:\\vs\\social_distance\\social_distance_openvino\\inputs\\street_area.mp4\")\n",
    "_,frame = video.read()\n",
    "width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
    "\n",
    "#give the output address to store the video \n",
    "writer = cv2.VideoWriter('C:\\vs\\social_distance\\social_distance_openvino\\results\\social_distance_openvino_optimized_version.avi', fourcc, 30,(width,height), True)\n",
    "\n",
    "# used to record the time when we processed last frame\n",
    "prev_frame_time = 0\n",
    "\n",
    "# used to record the time at which we processed current frame\n",
    "new_frame_time = 0\n",
    " \n",
    "while True:\n",
    "    # Read a frame from the video.\n",
    "    ret, frame = video.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break # Exit the loop if end of video or error\n",
    "    height, width = frame.shape[:2]\n",
    "   \n",
    "    # Preprocess the frame\n",
    "    image = cv2.resize(frame, (512,512))\n",
    "    image = image.transpose((2, 0, 1)) # Change data layout from HWC to CHW\n",
    "    \n",
    "    \n",
    "\n",
    "    # Run inference and get the output\n",
    "    infer_request = model.create_infer_request()\n",
    "    input_shape = [1,3,512,512]   \n",
    "    input_tensor= ov.Tensor(image.astype(np.float32))\n",
    "    input_tensor.shape = input_shape\n",
    "    infer_request.set_tensor(input_blob,input_tensor)\n",
    "    infer_request.infer()\n",
    "    output_tensor = infer_request.get_tensor(output_blob)\n",
    "    output = output_tensor.data\n",
    "    \n",
    "    \n",
    "\n",
    "    # Parse the output and get the bounding boxes of detected people\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    class_ids = []\n",
    "    \n",
    "    new_frame_time = time.time()\n",
    "    fps = 1/(new_frame_time-prev_frame_time)\n",
    "    prev_frame_time = new_frame_time\n",
    "    fps = int(fps)\n",
    "    fps = str(fps)\n",
    "    \n",
    "    for detection in output[0][0]:\n",
    "        # Each detection has the format [image_id, label, conf, x_min, y_min, x_max, y_max]\n",
    "        if detection[2] > 0.5: # Only keep detections with confidence > 0.5\n",
    "            class_id = int(detection[1])\n",
    "            if class_id == 0: # Only keep detections with label 0 (person)\n",
    "                x_min = int(detection[3] * width)\n",
    "                y_min = int(detection[4] * height)\n",
    "                x_max = int(detection[5] * width)\n",
    "                y_max = int(detection[6] * height)\n",
    "                boxes.append([x_min, y_min, x_max, y_max])\n",
    "                confidences.append(float(detection[2]))\n",
    "                class_ids.append(class_id)\n",
    "    \n",
    "    n = len(boxes)\n",
    "    # Apply non-maximum suppression to eliminate redundant overlapping boxes\n",
    "    indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "    \n",
    "    # Loop over the indices of the remaining boxes\n",
    "    v = 0\n",
    "    for i in indices:\n",
    "        box = boxes[i]\n",
    "        # Draw a bounding box around the person\n",
    "        cv2.rectangle(frame, (box[0], box[1]), (box[2], box[3]), (0, 255, 0), 2)\n",
    "        # Get the center point of the box\n",
    "        center_a = np.array([box[0] + (box[2] - box[0]) / 2, box[1] + (box[3] - box[1]) / 2])\n",
    "        \n",
    "        # Loop over the other indices of the remaining boxes\n",
    "        for j in indices:\n",
    "            if i != j: # Avoid comparing with itself\n",
    "                box_b = boxes[j]\n",
    "                # Get the center point of the other box\n",
    "                center_b = np.array([box_b[0] + (box_b[2] - box_b[0]) / 2, box_b[1] + (box_b[3] - box_b[1]) / 2])\n",
    "               \n",
    "                # Compute the distance between the two points\n",
    "                distance = euclidean_distance(center_a, center_b)\n",
    "                \n",
    "                # Check if the distance is below the threshold\n",
    "                if distance < distance_threshold:\n",
    "                    # Draw a red line between the two points\n",
    "                    v+=1\n",
    "                    cv2.line(frame, (int(center_a[0]), int(center_a[1])), (int(center_b[0]), int(center_b[1])), (0, 0, 255), 2)\n",
    "\n",
    "    # Show the output frame\n",
    "    cv2.imshow(\"Social Distance Detector\", frame)\n",
    "    cv2.putText(frame,'Number of Violations : '+str(v),(80,frame.shape[0]-10),cv2.FONT_HERSHEY_SIMPLEX,3,(0,0,255),3)\n",
    "    \n",
    "    cv2.putText(frame,\"FPS :\"+ fps, (7,70), cv2.FONT_HERSHEY_SIMPLEX, 3, (200,0,0), 3, cv2.LINE_AA)\n",
    "    writer.write(frame)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    # Wait for a key press to exit\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# Release the video and destroy the windows\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
